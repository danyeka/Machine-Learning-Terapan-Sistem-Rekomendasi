# -*- coding: utf-8 -*-
"""notebook_recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WPhKfvfYb0Z7ofcaN4s7I-8V_a4THjaU

# **Recommendation System**

## Deskripsi Proyek


Kemajuan teknologi digital telah membuka akses luas ke konten film, namun juga menimbulkan tantangan bagi pengguna untuk memilih film yang sesuai. Sistem rekomendasi film hadir sebagai solusi untuk membantu pengguna menemukan film yang relevan dengan preferensi mereka.

Dataset diambil dari [https://grouplens.org/datasets/movielens/100k/]
"""

# Langkah 1: Unduh file zip dari URL
!wget -O ml-latest-small.zip https://files.grouplens.org/datasets/movielens/ml-latest-small.zip

# Langkah 2: Unzip file
!unzip ml-latest-small.zip

"""## Import Library"""

!pip install surprise scikit-surprise

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""## Data Understanding

### Gathering Data
"""

links = pd.read_csv('/content/ml-latest-small/links.csv')
movies = pd.read_csv('/content/ml-latest-small/movies.csv')
ratings = pd.read_csv('/content/ml-latest-small/ratings.csv')
tags = pd.read_csv('/content/ml-latest-small/tags.csv')
display(links.head(), links.shape, movies.head(), movies.shape, ratings.head(), ratings.shape, tags.head(), tags.shape)

"""### Assessing Data

#### Checking Missing Value
"""

display(links.isnull().sum(), movies.isnull().sum(), ratings.isnull().sum(), tags.isnull().sum())

"""#### Checking Duplicate Data

"""

display(links.duplicated().sum(), movies.duplicated().sum(), ratings.duplicated().sum(), tags.duplicated().sum())

"""### Cleaning Data

### Exploratory Data Analysis (EDA)

#### Unique Value

##### Mengecek nilai unique untuk userid, movieid
"""

display(movies.movieId.nunique(), ratings.userId.nunique(), tags.userId.nunique(),
         tags.tag.nunique(), movies.genres.nunique())

"""##### Mengecek nilai unique genre"""

genres_split = movies.genres.str.split('|', expand=True)
genres_split.stack().unique()

"""##### Mengecek value counts tiap genre"""

genres_split = movies.genres.str.split('|').explode()
genre_counts = genres_split.value_counts()
genre_counts

"""#### Wordcloud

##### Inisiasi fungsi wordcloud
"""

from wordcloud import WordCloud

def wordcloud(data, title):
    wc = WordCloud(width=800, height=400, max_words=200, background_color='white').generate(' '.join(data))
    plt.figure(figsize=(10, 8))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(title)
    plt.show()

"""##### Wordcloud tags"""

wordcloud(tags.tag, 'Tags WordCloud')

"""##### Wordcloud untuk Genre"""

wordcloud(genres_split, 'Genres WordCloud')

wordcloud(movies.genres, 'Genres WordCloud')

"""#### Film berdasarkan Rating"""

display(movies.head(), ratings.head(), tags.head())

"""##### Menggabung data movies dan ratings"""

movies_ratings = pd.merge(movies, ratings, on='movieId')
display(movies_ratings.head(), movies_ratings.shape)

"""#### Rata rata rating terendah film"""

movies_ratings.groupby('title')['rating'].mean().sort_values(ascending=True).head(10)

"""#### Rata rata rating tertinggi film

"""

movies_ratings.groupby('title')['rating'].mean().sort_values(ascending=False).head(10)

"""#### Film yang paling banyak diberi rating"""

movies_ratings.groupby('title')['rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')

"""## Data Preparation

### General Data Preparation

Mengubah tipe data kolom timestamp menjadi datetime
"""

tags.timestamp = pd.to_datetime(tags.timestamp, unit='s')
ratings.timestamp = pd.to_datetime(ratings.timestamp, unit='s')
display(tags.head(), ratings.head())

"""Menggabung data movies dengan links"""

movies_full = pd.merge(movies, links, on='movieId')
display(movies_full.head(), movies_full.shape, movies_full.isnull().sum())

links[links.tmdbId.isnull()]

"""Membuang baris yang terdapat nilai kosong (null)"""

links.dropna(inplace=True)
display(links.head(),links.shape, links.isnull().sum())

"""Membersihkan tahun rilis judul film  """

movies['title'] = movies['title'].str.replace(r'\(\d{4}\)', '',
                                                        regex=True).str.strip()
movies['title'] = movies['title'].str.replace(r'\(\d{4}(â€“\d{4})?\)', '',
                                                        regex=True).str.strip()
display(movies, movies.isnull().sum())

"""Membersihkan kolom genres dengan menghapus karakter"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

tfidf = TfidfVectorizer(stop_words='english')

movies['genres'] = movies['genres'].str.replace(r"[\[\]']", "", regex=True).str.replace("|", " ")

movies['features'] = movies['title'] + " " + movies['genres']
movies

"""### Data Preparation untuk Modelling Content Based Filtering

Mengubah fitur judul film menjadi matriks TF-IDF, lalu menghitung kesamaan antarfilm menggunakan cosine similarity untuk mendapatkan nilai kemiripan setiap film satu sama lain.
"""

tfidf_matrix = tfidf.fit_transform(movies['features'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sim

"""### Data Preparation untuk Modelling Collaborative Filtering

Membagi data menjadi train dan test, lalu menghitung RMSE dan MAE untuk evaluasi akurasi model.
"""

from surprise.model_selection import train_test_split
from surprise import Reader, Dataset
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""# Model Development

## Content Based Filtering

Membuat fungsi untuk merekomendasikan 10 film mirip berdasarkan kesamaan judul yang diberikan, menggunakan cosine similarity.
"""

# Fungsi untuk rekomendasi film (Content Based Filtering menggunakan Cosine Similarity)
def recommend_movies(title, cosine_sim=cosine_sim):

    idx = movies[movies['title'] == title].index[0]

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    sim_scores = sim_scores[1:11]

    movie_indices = [i[0] for i in sim_scores]

    return movies.iloc[movie_indices][['movieId','title', 'genres']]

"""Kode ini akan menampilkan 10 rekomendasi film yang mirip dengan "Jumanji" berdasarkan kesamaan konten film."""

recommend_movies("Jumanji")

"""Menampilkan 10 rekomendasi film yang mirip dengan "Toy Story" berdasarkan kesamaan konten film."""

recommend_movies("Toy Story")

"""Fungsi-fungsi untuk menghitung metrik evaluasi untuk sistem rekomendasi"""

def precision_recall_content_based(input_movie, recommended_movies, k=10):
    input_tfidf = tfidf.transform([input_movie])
    rec_tfidf = tfidf.transform(recommended_movies)

    sim_scores = cosine_similarity(input_tfidf, rec_tfidf)[0]
    precision = sum(sim_scores[:k]) / k
    recall = sum(sim_scores[:k]) / sum(sim_scores) if sum(sim_scores) > 0 else 0
    return precision * 100, recall * 100

input_movies = ["Toy Story", "Jumanji"]
recommendation_results = {movie: list(recommend_movies(movie)['title']) for movie in input_movies}

for movie in input_movies:
    recommended_titles = recommendation_results[movie]
    precision, recall = precision_recall_content_based(movie, recommended_titles, k=5)
    print(f"Precision@5 for '{movie}': {precision:.2f}%")
    print(f"Recall@5 for '{movie}': {recall:.2f}%")

"""## Collaborative Filtering"""

from surprise.model_selection import train_test_split
from surprise import SVD, Dataset, Reader
from surprise.model_selection import cross_validate
from surprise.accuracy import rmse, mae

"""Melatih model SVD untuk rekomendasi film"""

model = SVD()

model.fit(trainset)

predictions = model.test(testset)
print("Root Mean Squared Error (RMSE):", rmse(predictions))
print("Mean Absolute Error (MAE):", mae(predictions))

"""Fungsi ini merekomendasikan 10 film teratas yang belum pernah ditonton oleh pengguna berdasarkan prediksi rating model."""

def get_recommendations(user_id, movies_df, top_n=10):
    user_rated_movies = ratings[ratings['userId'] == user_id]['movieId'].values
    all_movie_ids = movies_df['movieId'].unique()
    unrated_movie_ids = np.setdiff1d(all_movie_ids, user_rated_movies)

    predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movie_ids]
    predictions.sort(key=lambda x: x.est, reverse=True)

    recommended_movie_ids = [pred.iid for pred in predictions[:top_n]]
    recommendations = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]
    return recommendations[['title', 'genres']]

"""Rekomendasi film untuk user id 331"""

get_recommendations(331, movies)

"""Rekomendasi film untuk user id 1"""

user_id = 1
recommended_movies = get_recommendations(user_id, movies)
print("Recommended Movies for User", user_id)
print(recommended_movies)